{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Databricks App — Interactive Retail Analytics\n",
        "\n",
        "Deploys a Gradio web app as a Databricks App with four tabs:\n",
        "Customer 360, Revenue Explorer, Product Analytics, and Executive KPIs.\n",
        "\n",
        "Queries run via the Databricks SDK Statement Execution API (no extra SQL driver needed).\n",
        "\n",
        "**Prereqs**: Run notebooks 00–08 first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 — Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "CATALOG = spark.catalog.currentCatalog()\n",
        "GOLD    = f\"{CATALOG}.retail_gold\"\n",
        "SILVER  = f\"{CATALOG}.retail_silver\"\n",
        "\n",
        "# SQL warehouse for the app to use — update this to match your workspace\n",
        "WAREHOUSE_ID = dbutils.widgets.get(\"warehouse_id\") if \"warehouse_id\" in [w.name for w in dbutils.widgets.getAll()] else \"\"\n",
        "if not WAREHOUSE_ID:\n",
        "    # Fallback: pick the first available warehouse via SDK\n",
        "    from databricks.sdk import WorkspaceClient\n",
        "    w = WorkspaceClient()\n",
        "    wh_list = [wh for wh in w.warehouses.list() if str(wh.state) in (\"RUNNING\", \"STOPPED\")]\n",
        "    WAREHOUSE_ID = wh_list[0].id if wh_list else \"\"\n",
        "    print(f\"Auto-detected warehouse: {WAREHOUSE_ID}\")\n",
        "\n",
        "APP_NAME = \"retail-analytics-app\"\n",
        "APP_DIR  = \"/Workspace/Users/{}/apps/retail_analytics\".format(\n",
        "    spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        ")\n",
        "\n",
        "print(f\"Catalog      : {CATALOG}\")\n",
        "print(f\"Gold         : {GOLD}\")\n",
        "print(f\"Warehouse    : {WAREHOUSE_ID}\")\n",
        "print(f\"App Dir      : {APP_DIR}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 — Create App Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "os.makedirs(APP_DIR, exist_ok=True)\n",
        "print(f\"✓ App directory: {APP_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "328f6f61"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 — Write the Gradio App Code\n",
        "\n",
        "The app uses `databricks.sql` connector to query Gold tables and renders results with Gradio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Write app.py using base64 to avoid all string escaping issues\n",
        "import base64\n",
        "\n",
        "# This is the app.py content, base64-encoded to survive notebook JSON escaping\n",
        "_b64 = base64.b64encode(open(\"/dev/null\", \"rb\").read())  # placeholder\n",
        "\n",
        "# Build the app source code programmatically (no nested string literals)\n",
        "_lines = []\n",
        "_lines.append(\"import os\")\n",
        "_lines.append(\"import logging\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"import gradio as gr\")\n",
        "_lines.append(\"import pandas as pd\")\n",
        "_lines.append(\"from databricks.sdk import WorkspaceClient\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"logging.basicConfig(level=logging.INFO)\")\n",
        "_lines.append(\"logger = logging.getLogger(__name__)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"CATALOG = os.getenv('CATALOG', '\" + CATALOG + \"')\")\n",
        "_lines.append(\"GOLD = CATALOG + '.retail_gold'\")\n",
        "_lines.append(\"SILVER = CATALOG + '.retail_silver'\")\n",
        "_lines.append(\"WAREHOUSE_ID = os.getenv('DATABRICKS_WAREHOUSE_ID', '')\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def run_query(sql):\")\n",
        "_lines.append(\"    try:\")\n",
        "_lines.append(\"        w = WorkspaceClient()\")\n",
        "_lines.append(\"        resp = w.statement_execution.execute_statement(\")\n",
        "_lines.append(\"            warehouse_id=WAREHOUSE_ID, statement=sql, wait_timeout='30s')\")\n",
        "_lines.append(\"        if resp.result and resp.manifest:\")\n",
        "_lines.append(\"            cols = [c.name for c in resp.manifest.schema.columns]\")\n",
        "_lines.append(\"            rows = resp.result.data_array or []\")\n",
        "_lines.append(\"            return pd.DataFrame(rows, columns=cols)\")\n",
        "_lines.append(\"        return pd.DataFrame()\")\n",
        "_lines.append(\"    except Exception as e:\")\n",
        "_lines.append(\"        logger.error('Query failed: %s', e)\")\n",
        "_lines.append(\"        return pd.DataFrame({'error': [str(e)]})\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def customer_lookup(customer_id):\")\n",
        "_lines.append(\"    try:\")\n",
        "_lines.append(\"        cid = int(customer_id)\")\n",
        "_lines.append(\"    except (ValueError, TypeError):\")\n",
        "_lines.append(\"        return 'Enter a valid customer ID (integer).', None\")\n",
        "_lines.append(\"    sql = 'SELECT c.customer_key, c.customer_name, c.market_segment, '\")\n",
        "_lines.append(\"    sql += 'c.nation_name, c.region_name, c.balance_tier, '\")\n",
        "_lines.append(\"    sql += 'r.rfm_segment, r.rfm_score, ROUND(r.monetary,2) as lifetime_value, '\")\n",
        "_lines.append(\"    sql += 'r.frequency as total_orders, r.recency_days, '\")\n",
        "_lines.append(\"    sql += 'ROUND(r.avg_order_value,2) as avg_order_value '\")\n",
        "_lines.append(\"    sql += 'FROM ' + SILVER + '.dim_customer c '\")\n",
        "_lines.append(\"    sql += 'LEFT JOIN ' + GOLD + '.gold_customer_rfm r '\")\n",
        "_lines.append(\"    sql += 'ON c.customer_key = r.customer_key '\")\n",
        "_lines.append(\"    sql += 'WHERE c.customer_key = ' + str(cid)\")\n",
        "_lines.append(\"    profile = run_query(sql)\")\n",
        "_lines.append(\"    if 'error' in profile.columns:\")\n",
        "_lines.append(\"        return 'Query error: ' + str(profile['error'].iloc[0]), None\")\n",
        "_lines.append(\"    if profile.empty:\")\n",
        "_lines.append(\"        return 'Customer ' + str(cid) + ' not found.', None\")\n",
        "_lines.append(\"    r = profile.iloc[0]\")\n",
        "_lines.append(\"    md = '## Customer #' + str(r.get('customer_key','')) + ' - ' + str(r.get('customer_name',''))\")\n",
        "_lines.append(\"    md += '\\\\n\\\\n| Attribute | Value |\\\\n|---|---|'\")\n",
        "_lines.append(\"    md += '\\\\n| Segment | ' + str(r.get('market_segment','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Region | ' + str(r.get('region_name','')) + ' (' + str(r.get('nation_name','')) + ') |'\")\n",
        "_lines.append(\"    md += '\\\\n| RFM Segment | ' + str(r.get('rfm_segment','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Lifetime Value | ' + str(r.get('lifetime_value','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Total Orders | ' + str(r.get('total_orders','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Avg Order Value | ' + str(r.get('avg_order_value','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Recency (days) | ' + str(r.get('recency_days','')) + ' |'\")\n",
        "_lines.append(\"    return md, profile\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def revenue_explorer(region, start_month, end_month):\")\n",
        "_lines.append(\"    w = 'WHERE 1=1'\")\n",
        "_lines.append(\"    if region != 'ALL':\")\n",
        "_lines.append(\"        w += \\\" AND region = '\\\" + region + \\\"'\\\"\")\n",
        "_lines.append(\"    if start_month:\")\n",
        "_lines.append(\"        w += \\\" AND year_month >= '\\\" + start_month + \\\"'\\\"\")\n",
        "_lines.append(\"    if end_month:\")\n",
        "_lines.append(\"        w += \\\" AND year_month <= '\\\" + end_month + \\\"'\\\"\")\n",
        "_lines.append(\"    sql = 'SELECT year_month, region, ROUND(SUM(net_revenue),0) as net_revenue, '\")\n",
        "_lines.append(\"    sql += 'SUM(num_orders) as orders, ROUND(AVG(profit_margin_pct),1) as margin_pct '\")\n",
        "_lines.append(\"    sql += 'FROM ' + GOLD + '.gold_monthly_sales ' + w\")\n",
        "_lines.append(\"    sql += ' GROUP BY year_month, region ORDER BY year_month, region'\")\n",
        "_lines.append(\"    df = run_query(sql)\")\n",
        "_lines.append(\"    if 'error' in df.columns:\")\n",
        "_lines.append(\"        return 'Query error: ' + str(df['error'].iloc[0]), df\")\n",
        "_lines.append(\"    total = pd.to_numeric(df['net_revenue'], errors='coerce').sum()\")\n",
        "_lines.append(\"    return '**Revenue**: ${:,.0f} | **Rows**: {}'.format(total, len(df)), df\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def product_analytics(sort_by, top_n):\")\n",
        "_lines.append(\"    sql = 'SELECT brand, price_band, ROUND(SUM(net_revenue),0) as net_revenue, '\")\n",
        "_lines.append(\"    sql += 'ROUND(AVG(profit_margin_pct),1) as margin_pct, '\")\n",
        "_lines.append(\"    sql += 'ROUND(AVG(return_rate_pct),1) as return_rate_pct, '\")\n",
        "_lines.append(\"    sql += 'SUM(num_orders) as orders '\")\n",
        "_lines.append(\"    sql += 'FROM ' + GOLD + '.gold_product_performance '\")\n",
        "_lines.append(\"    sql += 'GROUP BY brand, price_band ORDER BY ' + sort_by + ' DESC '\")\n",
        "_lines.append(\"    sql += 'LIMIT ' + str(int(top_n))\")\n",
        "_lines.append(\"    return run_query(sql)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def executive_kpis():\")\n",
        "_lines.append(\"    sql = 'SELECT year_quarter, total_orders, active_customers, '\")\n",
        "_lines.append(\"    sql += 'ROUND(gross_order_value,0) as gross_order_value, '\")\n",
        "_lines.append(\"    sql += 'ROUND(avg_order_value,0) as avg_order_value, '\")\n",
        "_lines.append(\"    sql += 'ROUND(revenue_per_customer,0) as rev_per_customer, '\")\n",
        "_lines.append(\"    sql += 'qoq_revenue_growth_pct '\")\n",
        "_lines.append(\"    sql += 'FROM ' + GOLD + '.gold_executive_summary ORDER BY year_quarter'\")\n",
        "_lines.append(\"    return run_query(sql)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"with gr.Blocks(title='Retail Analytics', theme=gr.themes.Soft()) as app:\")\n",
        "_lines.append(\"    gr.Markdown('# Retail Analytics Dashboard')\")\n",
        "_lines.append(\"    gr.Markdown('Powered by **Databricks Lakehouse**')\")\n",
        "_lines.append(\"    with gr.Tab('Customer 360'):\")\n",
        "_lines.append(\"        gr.Markdown('### Look up any customer by ID')\")\n",
        "_lines.append(\"        with gr.Row():\")\n",
        "_lines.append(\"            ci = gr.Textbox(label='Customer ID', placeholder='e.g. 42', scale=1)\")\n",
        "_lines.append(\"            cb = gr.Button('Look Up', variant='primary', scale=1)\")\n",
        "_lines.append(\"        cm = gr.Markdown()\")\n",
        "_lines.append(\"        ct = gr.Dataframe(label='Raw Profile')\")\n",
        "_lines.append(\"        cb.click(customer_lookup, inputs=ci, outputs=[cm, ct])\")\n",
        "_lines.append(\"    with gr.Tab('Revenue Explorer'):\")\n",
        "_lines.append(\"        gr.Markdown('### Monthly revenue by region')\")\n",
        "_lines.append(\"        with gr.Row():\")\n",
        "_lines.append(\"            rd = gr.Dropdown(choices=['ALL','AMERICA','EUROPE','ASIA','AFRICA','MIDDLE EAST'], value='ALL', label='Region')\")\n",
        "_lines.append(\"            sm = gr.Textbox(label='Start (yyyy-MM)', value='1995-01')\")\n",
        "_lines.append(\"            em = gr.Textbox(label='End (yyyy-MM)', value='1997-12')\")\n",
        "_lines.append(\"            rb = gr.Button('Query', variant='primary')\")\n",
        "_lines.append(\"        rs = gr.Markdown()\")\n",
        "_lines.append(\"        rt = gr.Dataframe(label='Revenue Data')\")\n",
        "_lines.append(\"        rb.click(revenue_explorer, inputs=[rd, sm, em], outputs=[rs, rt])\")\n",
        "_lines.append(\"    with gr.Tab('Product Analytics'):\")\n",
        "_lines.append(\"        gr.Markdown('### Product performance by brand')\")\n",
        "_lines.append(\"        with gr.Row():\")\n",
        "_lines.append(\"            sd = gr.Dropdown(choices=['net_revenue','margin_pct','return_rate_pct','orders'], value='net_revenue', label='Sort By')\")\n",
        "_lines.append(\"            tn = gr.Slider(minimum=5, maximum=50, value=20, step=5, label='Top N')\")\n",
        "_lines.append(\"            pb = gr.Button('Query', variant='primary')\")\n",
        "_lines.append(\"        pt = gr.Dataframe(label='Product Performance')\")\n",
        "_lines.append(\"        pb.click(product_analytics, inputs=[sd, tn], outputs=pt)\")\n",
        "_lines.append(\"    with gr.Tab('Executive KPIs'):\")\n",
        "_lines.append(\"        gr.Markdown('### Quarterly executive summary')\")\n",
        "_lines.append(\"        eb = gr.Button('Load KPIs', variant='primary')\")\n",
        "_lines.append(\"        et = gr.Dataframe(label='Quarterly KPIs')\")\n",
        "_lines.append(\"        eb.click(executive_kpis, outputs=et)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"if __name__ == '__main__':\")\n",
        "_lines.append(\"    logger.info('Starting Retail Analytics App (catalog=%s)', CATALOG)\")\n",
        "_lines.append(\"    app.launch(server_name='0.0.0.0', server_port=int(os.getenv('PORT', '8000')))\")\n",
        "\n",
        "app_code = \"\\n\".join(_lines) + \"\\n\"\n",
        "app_file = f\"{APP_DIR}/app.py\"\n",
        "with open(app_file, \"w\") as f:\n",
        "    f.write(app_code)\n",
        "print(f\"✓ App code written to: {app_file}\")\n",
        "print(f\"  Lines: {len(_lines)}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4161f5de"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 — Write App Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "config_content = f\"\"\"command:\n",
        "- python\n",
        "- app.py\n",
        "env:\n",
        "- name: CATALOG\n",
        "  value: {CATALOG}\n",
        "- name: DATABRICKS_WAREHOUSE_ID\n",
        "  value: {WAREHOUSE_ID}\n",
        "\"\"\"\n",
        "\n",
        "config_file = f\"{APP_DIR}/app.yaml\"\n",
        "\n",
        "with open(config_file, \"w\") as f:\n",
        "    f.write(config_content)\n",
        "print(f\"✓ App config: {config_file}\")\n",
        "print(config_content)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "997673d0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Requirements file — databricks-sdk is pre-installed in app runtime\n",
        "requirements = \"\"\"gradio>=4.0\n",
        "databricks-sdk\n",
        "pandas\n",
        "\"\"\"\n",
        "\n",
        "req_file = f\"{APP_DIR}/requirements.txt\"\n",
        "\n",
        "with open(req_file, \"w\") as f:\n",
        "    f.write(requirements)\n",
        "print(f\"✓ Requirements: {req_file}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "51daed5d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 — Deploy the Databricks App"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pip install databricks-sdk --upgrade --quiet"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5b6b432a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import requests, time, json\n",
        "\n",
        "# Re-init variables (kernel may restart between cells)\n",
        "CATALOG  = spark.catalog.currentCatalog()\n",
        "GOLD     = f\"{CATALOG}.retail_gold\"\n",
        "SILVER   = f\"{CATALOG}.retail_silver\"\n",
        "APP_NAME = \"retail-analytics-app\"\n",
        "APP_DIR  = \"/Workspace/Users/{}/apps/retail_analytics\".format(\n",
        "    spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        ")\n",
        "\n",
        "# Re-detect warehouse\n",
        "from databricks.sdk import WorkspaceClient as _WC\n",
        "_w = _WC()\n",
        "_wh = [wh for wh in _w.warehouses.list() if str(wh.state) in (\"RUNNING\", \"STOPPED\")]\n",
        "WAREHOUSE_ID = _wh[0].id if _wh else \"\"\n",
        "\n",
        "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
        "db_host  = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
        "headers  = {\"Authorization\": f\"Bearer {db_token}\", \"Content-Type\": \"application/json\"}\n",
        "base     = f\"https://{db_host}/api/2.0/apps\"\n",
        "\n",
        "# ── Step A: Create the app via REST API ───────────────────────────────────────\n",
        "print(\"Creating app...\")\n",
        "resp = requests.post(base, headers=headers, json={\n",
        "    \"name\": APP_NAME,\n",
        "    \"description\": \"Retail analytics dashboard — Gold-layer Delta tables\",\n",
        "    \"resources\": [\n",
        "        {\"name\": \"sql-warehouse\", \"sql_warehouse\": {\"id\": WAREHOUSE_ID, \"permission\": \"CAN_USE\"}},\n",
        "    ],\n",
        "})\n",
        "if resp.status_code == 200:\n",
        "    app_data = resp.json()\n",
        "    print(f\"✓ App created: {APP_NAME}\")\n",
        "    print(f\"  App URL: {app_data.get('url', 'pending...')}\")\n",
        "elif resp.status_code == 409:\n",
        "    print(f\"○ App '{APP_NAME}' already exists — reusing it\")\n",
        "else:\n",
        "    print(f\"⚠ App creation ({resp.status_code}): {resp.text[:300]}\")\n",
        "\n",
        "# ── Step B: Deploy source code via REST API ───────────────────────────────────\n",
        "print(\"\\nDeploying app...\")\n",
        "resp = requests.post(f\"{base}/{APP_NAME}/deployments\", headers=headers, json={\n",
        "    \"source_code_path\": APP_DIR,\n",
        "    \"mode\": \"SNAPSHOT\",\n",
        "})\n",
        "if resp.status_code == 200:\n",
        "    dep = resp.json()\n",
        "    dep_id = dep.get(\"deployment_id\", \"\")\n",
        "    print(f\"✓ Deployment started: {dep_id}\")\n",
        "\n",
        "    # Poll until deployment completes (up to 5 min)\n",
        "    for i in range(30):\n",
        "        time.sleep(10)\n",
        "        status_resp = requests.get(f\"{base}/{APP_NAME}/deployments/{dep_id}\", headers=headers)\n",
        "        if status_resp.status_code == 200:\n",
        "            state = status_resp.json().get(\"status\", {}).get(\"state\", \"\")\n",
        "            print(f\"  [{i*10}s] Status: {state}\")\n",
        "            if state == \"SUCCEEDED\":\n",
        "                # Get the app URL\n",
        "                app_resp = requests.get(f\"{base}/{APP_NAME}\", headers=headers)\n",
        "                if app_resp.status_code == 200:\n",
        "                    app_url = app_resp.json().get(\"url\", \"\")\n",
        "                    print(f\"\\n✓ App deployed successfully!\")\n",
        "                    print(f\"  URL: https://{app_url}\")\n",
        "                break\n",
        "            elif state == \"FAILED\":\n",
        "                msg = status_resp.json().get(\"status\", {}).get(\"message\", \"\")\n",
        "                print(f\"\\n✗ Deployment failed: {msg}\")\n",
        "                break\n",
        "    else:\n",
        "        print(\"  Deployment still in progress — check Compute → Apps in the UI\")\n",
        "else:\n",
        "    print(f\"⚠ Deployment ({resp.status_code}): {resp.text[:300]}\")\n",
        "    print(f\"\\nManual deployment:\")\n",
        "    print(f\"  1. Go to Compute → Apps → click '{APP_NAME}'\")\n",
        "    print(f\"  2. Create a new deployment with source: {APP_DIR}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0817adb0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5b — Grant App Service Principal Access to Data\n",
        "\n",
        "The Databricks App runs under its own service principal. It needs explicit grants to read your Unity Catalog tables."
      ],
      "id": "e881815d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Look up the app's service principal\n",
        "import requests, json\n",
        "\n",
        "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
        "db_host  = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
        "headers  = {\"Authorization\": f\"Bearer {db_token}\", \"Content-Type\": \"application/json\"}\n",
        "\n",
        "resp = requests.get(\n",
        "    f\"https://{db_host}/api/2.0/apps/{APP_NAME}\",\n",
        "    headers=headers,\n",
        ")\n",
        "app_info = resp.json()\n",
        "sp_name = app_info.get(\"service_principal_name\", \"\")\n",
        "sp_id   = app_info.get(\"service_principal_id\", \"\")\n",
        "\n",
        "print(f\"App service principal: {sp_name} (id={sp_id})\")\n",
        "\n",
        "if sp_name:\n",
        "    # Grant the service principal access to the catalog and schemas\n",
        "    grants = [\n",
        "        f\"GRANT USE CATALOG ON CATALOG {CATALOG} TO `{sp_name}`\",\n",
        "        f\"GRANT USE SCHEMA ON SCHEMA {CATALOG}.retail_gold TO `{sp_name}`\",\n",
        "        f\"GRANT USE SCHEMA ON SCHEMA {CATALOG}.retail_silver TO `{sp_name}`\",\n",
        "        f\"GRANT SELECT ON SCHEMA {CATALOG}.retail_gold TO `{sp_name}`\",\n",
        "        f\"GRANT SELECT ON SCHEMA {CATALOG}.retail_silver TO `{sp_name}`\",\n",
        "    ]\n",
        "    for sql in grants:\n",
        "        try:\n",
        "            spark.sql(sql)\n",
        "            print(f\"  ✓ {sql.split('GRANT ')[1][:60]}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ⚠ {sql.split('GRANT ')[1][:40]}... → {str(e)[:80]}\")\n",
        "\n",
        "    print(f\"\\n✓ Permissions granted. Restart the app or try again.\")\n",
        "else:\n",
        "    print(\"⚠ Could not find app service principal. Grant permissions manually:\")\n",
        "    print(f\"  GRANT USE CATALOG ON CATALOG {CATALOG} TO `<app_service_principal>`\")\n",
        "    print(f\"  GRANT SELECT ON SCHEMA {CATALOG}.retail_gold TO `<app_service_principal>`\")\n",
        "    print(f\"  GRANT SELECT ON SCHEMA {CATALOG}.retail_silver TO `<app_service_principal>`\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "05a70f8b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 — Verify App Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "print(f\"App directory contents ({APP_DIR}):\")\n",
        "for name in os.listdir(APP_DIR):\n",
        "    full = os.path.join(APP_DIR, name)\n",
        "    size = os.path.getsize(full) if os.path.isfile(full) else 0\n",
        "    print(f\"  {name:<25} {size:>8} bytes\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "747ee556"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7 — Quick Smoke Test (Query Gold from notebook)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify the same queries the app will run\n",
        "print(\"Smoke test — queries that the app executes:\\n\")\n",
        "\n",
        "print(\"1. Customer lookup (ID=42):\")\n",
        "display(spark.sql(f\"\"\"\n",
        "    SELECT c.customer_key, c.customer_name, c.market_segment, c.region_name,\n",
        "           r.rfm_segment, r.rfm_score, ROUND(r.monetary, 2) as ltv\n",
        "    FROM {SILVER}.dim_customer c\n",
        "    LEFT JOIN {GOLD}.gold_customer_rfm r ON c.customer_key = r.customer_key\n",
        "    WHERE c.customer_key = 42\n",
        "\"\"\"))\n",
        "\n",
        "print(\"\\n2. Revenue summary (AMERICA, 1996):\")\n",
        "display(spark.sql(f\"\"\"\n",
        "    SELECT year_month, region, ROUND(SUM(net_revenue), 0) as net_revenue\n",
        "    FROM {GOLD}.gold_monthly_sales\n",
        "    WHERE region = 'AMERICA' AND year_month >= '1996-01' AND year_month <= '1996-12'\n",
        "    GROUP BY year_month, region\n",
        "    ORDER BY year_month\n",
        "\"\"\"))\n",
        "\n",
        "print(\"\\n3. Top 5 brands:\")\n",
        "display(spark.sql(f\"\"\"\n",
        "    SELECT brand, ROUND(SUM(net_revenue), 0) as revenue\n",
        "    FROM {GOLD}.gold_product_performance\n",
        "    GROUP BY brand\n",
        "    ORDER BY revenue DESC\n",
        "    LIMIT 5\n",
        "\"\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "App deployed. Open the URL printed above to use it.\n",
        "\n",
        "This is the last notebook — the full pipeline is now live."
      ],
      "id": "25e41400"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}