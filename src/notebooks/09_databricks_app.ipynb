{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Frontend App with Databricks Lakehouse Applications\n",
    "\n",
    "Writes and deploys a Gradio application as a\n",
    "[Databricks App](https://docs.databricks.com/en/dev-tools/databricks-apps/).\n",
    "The app queries Gold and Silver-layer Delta tables through the Statement\n",
    "Execution API and renders five interactive tabs: Customer 360, Revenue Trends,\n",
    "Product Analytics, Churn Risk, and Executive Summary.\n",
    "\n",
    "**Prerequisites** -- run notebooks `00` through `08` first so the Gold tables\n",
    "and ML scores exist."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "%pip install --quiet -U databricks-sdk>=0.59.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "CATALOG = spark.catalog.currentCatalog()\n",
    "GOLD    = f\"{CATALOG}.retail_gold\"\n",
    "SILVER  = f\"{CATALOG}.retail_silver\"\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "WAREHOUSE_ID = \"\"\n",
    "for wh in w.warehouses.list():\n",
    "    state_str = str(wh.state).upper()\n",
    "    print(f\"  Found warehouse: {wh.name} (id={wh.id}, state={wh.state})\")\n",
    "    if not WAREHOUSE_ID and (\"RUNNING\" in state_str or \"STOPPED\" in state_str):\n",
    "        WAREHOUSE_ID = wh.id\n",
    "\n",
    "if not WAREHOUSE_ID:\n",
    "    print(\"No running/stopped warehouse detected. Set WAREHOUSE_ID manually below:\")\n",
    "    # WAREHOUSE_ID = \"paste-your-warehouse-id-here\"\n",
    "\n",
    "current_user = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "APP_NAME = \"retail-analytics-app\"\n",
    "APP_DIR  = f\"/Workspace/Users/{current_user}/apps/retail_analytics\"\n",
    "\n",
    "print(f\"\\nCatalog   : {CATALOG}\")\n",
    "print(f\"Warehouse : {WAREHOUSE_ID}\")\n",
    "print(f\"App dir   : {APP_DIR}\")\n",
    "print(f\"App name  : {APP_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write App Files\n",
    "\n",
    "The application lives in three files written to `APP_DIR`:\n",
    "\n",
    "| File | Purpose |\n",
    "|---|---|\n",
    "| `app.py` | Gradio frontend with five tabs, backed by SQL queries |\n",
    "| `app.yaml` | Runtime config: start command + environment variables |\n",
    "| `requirements.txt` | Python dependencies installed at deploy time |\n",
    "\n",
    "`DATABRICKS_WAREHOUSE_ID` is resolved from the app resource binding (`valueFrom`),\n",
    "following the pattern from [databricks/app-templates](https://github.com/databricks/app-templates)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.makedirs(APP_DIR, exist_ok=True)\n",
    "\n",
    "yaml_content = f\"\"\"command:\n",
    "  - python\n",
    "  - app.py\n",
    "env:\n",
    "  - name: DATABRICKS_WAREHOUSE_ID\n",
    "    valueFrom: sql-warehouse\n",
    "  - name: CATALOG\n",
    "    value: {CATALOG}\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{APP_DIR}/app.yaml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "print(f\"Wrote {APP_DIR}/app.yaml\")\n",
    "\n",
    "reqs = \"\"\"gradio>=4.0\n",
    "databricks-sdk\n",
    "pandas\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{APP_DIR}/requirements.txt\", \"w\") as f:\n",
    "    f.write(reqs)\n",
    "print(f\"Wrote {APP_DIR}/requirements.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "app_source = '''\"\"\"Retail Analytics Dashboard -- Gradio app backed by Gold-layer Delta tables.\"\"\"\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# -- Configuration ----------------------------------------------------------------\n",
    "CATALOG      = os.getenv(\"CATALOG\", \"main\")\n",
    "GOLD         = f\"{CATALOG}.retail_gold\"\n",
    "SILVER       = f\"{CATALOG}.retail_silver\"\n",
    "WAREHOUSE_ID = os.getenv(\"DATABRICKS_WAREHOUSE_ID\", \"\")\n",
    "\n",
    "assert WAREHOUSE_ID, \"DATABRICKS_WAREHOUSE_ID must be set in app.yaml.\"\n",
    "\n",
    "w = WorkspaceClient()\n",
    "\n",
    "\n",
    "def run_query(sql: str) -> pd.DataFrame:\n",
    "    \"\"\"Execute a SQL query via the Statement Execution API.\"\"\"\n",
    "    try:\n",
    "        resp = w.statement_execution.execute_statement(\n",
    "            warehouse_id=WAREHOUSE_ID, statement=sql, wait_timeout=\"30s\"\n",
    "        )\n",
    "        if resp.result and resp.manifest:\n",
    "            cols = [c.name for c in resp.manifest.schema.columns]\n",
    "            rows = resp.result.data_array or []\n",
    "            df = pd.DataFrame(rows, columns=cols)\n",
    "            for c in df.columns:\n",
    "                df[c] = pd.to_numeric(df[c], errors=\"ignore\")\n",
    "            return df\n",
    "        return pd.DataFrame()\n",
    "    except Exception as exc:\n",
    "        logger.error(\"Query failed: %s\", exc)\n",
    "        return pd.DataFrame({\"error\": [str(exc)]})\n",
    "\n",
    "\n",
    "# -- Tab: Customer 360 ------------------------------------------------------------\n",
    "def customer_lookup(customer_id):\n",
    "    \"\"\"Look up a single customer by key.\"\"\"\n",
    "    if not customer_id or not str(customer_id).strip():\n",
    "        return \"Enter a customer ID to look up.\", None\n",
    "    try:\n",
    "        cid = int(customer_id)\n",
    "    except (ValueError, TypeError):\n",
    "        return \"Enter a valid integer customer ID.\", None\n",
    "\n",
    "    df = run_query(f\"\"\"\n",
    "        SELECT c.customer_key, c.customer_name, c.market_segment,\n",
    "               c.nation_name, c.region_name, c.balance_tier,\n",
    "               r.rfm_segment, r.rfm_score,\n",
    "               ROUND(r.monetary, 2) AS lifetime_value,\n",
    "               r.frequency AS total_orders, r.recency_days,\n",
    "               ROUND(r.avg_order_value, 2) AS avg_order_value\n",
    "        FROM {SILVER}.dim_customer c\n",
    "        LEFT JOIN {GOLD}.gold_customer_rfm r ON c.customer_key = r.customer_key\n",
    "        WHERE c.customer_key = {cid}\n",
    "    \"\"\")\n",
    "\n",
    "    if \"error\" in df.columns:\n",
    "        return f\"Query error: {df['error'].iloc[0]}\", None\n",
    "    if df.empty:\n",
    "        return f\"No customer found with ID {cid}.\", None\n",
    "\n",
    "    r = df.iloc[0]\n",
    "    summary = f\"\"\"## Customer #{r['customer_key']} -- {r['customer_name']}\n",
    "\n",
    "| Attribute | Value |\n",
    "|---|---|\n",
    "| Segment | {r['market_segment']} |\n",
    "| Region | {r['region_name']} ({r['nation_name']}) |\n",
    "| Balance Tier | {r.get('balance_tier', 'N/A')} |\n",
    "| RFM Segment | {r['rfm_segment']} |\n",
    "| RFM Score | {r['rfm_score']} |\n",
    "| Lifetime Value | ${float(r['lifetime_value']):,.2f} |\n",
    "| Total Orders | {r['total_orders']} |\n",
    "| Avg Order Value | ${float(r['avg_order_value']):,.2f} |\n",
    "| Recency (days) | {r['recency_days']} |\n",
    "\"\"\"\n",
    "    return summary, df\n",
    "\n",
    "\n",
    "# -- Tab: Revenue ------------------------------------------------------------------\n",
    "def revenue_data(region, start_month, end_month):\n",
    "    \"\"\"Monthly revenue by region with optional filters.\"\"\"\n",
    "    clauses = []\n",
    "    if region and region != \"ALL\":\n",
    "        clauses.append(f\"region = '{region}'\")\n",
    "    if start_month:\n",
    "        clauses.append(f\"year_month >= '{start_month}'\")\n",
    "    if end_month:\n",
    "        clauses.append(f\"year_month <= '{end_month}'\")\n",
    "    where = \"WHERE \" + \" AND \".join(clauses) if clauses else \"\"\n",
    "\n",
    "    df = run_query(f\"\"\"\n",
    "        SELECT year_month, region,\n",
    "               ROUND(SUM(net_revenue), 0) AS revenue,\n",
    "               SUM(num_orders) AS orders,\n",
    "               ROUND(AVG(profit_margin_pct), 1) AS margin_pct\n",
    "        FROM {GOLD}.gold_monthly_sales\n",
    "        {where}\n",
    "        GROUP BY year_month, region ORDER BY year_month, region\n",
    "    \"\"\")\n",
    "\n",
    "    if \"error\" in df.columns:\n",
    "        return f\"Query error: {df['error'].iloc[0]}\", df\n",
    "\n",
    "    total = df[\"revenue\"].sum()\n",
    "    header = f\"**Total Revenue**: ${total:,.0f}  |  **Rows**: {len(df)}\"\n",
    "    return header, df\n",
    "\n",
    "\n",
    "# -- Tab: Products -----------------------------------------------------------------\n",
    "def product_data(sort_by, top_n):\n",
    "    \"\"\"Top products by brand and price band.\"\"\"\n",
    "    return run_query(f\"\"\"\n",
    "        SELECT brand, price_band,\n",
    "               ROUND(SUM(net_revenue), 0) AS revenue,\n",
    "               ROUND(AVG(profit_margin_pct), 1) AS margin_pct,\n",
    "               ROUND(AVG(return_rate_pct), 1) AS return_rate,\n",
    "               SUM(num_orders) AS orders\n",
    "        FROM {GOLD}.gold_product_performance\n",
    "        GROUP BY brand, price_band ORDER BY {sort_by} DESC LIMIT {int(top_n)}\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "# -- Tab: Churn Risk ---------------------------------------------------------------\n",
    "def churn_data():\n",
    "    \"\"\"Churn risk tier breakdown and the 50 highest-risk customers.\"\"\"\n",
    "    summary_df = run_query(f\"\"\"\n",
    "        SELECT risk_tier, COUNT(*) AS customers,\n",
    "               ROUND(AVG(churn_probability), 3) AS avg_probability,\n",
    "               ROUND(AVG(lifetime_value), 0) AS avg_ltv\n",
    "        FROM {GOLD}.gold_churn_scores\n",
    "        GROUP BY risk_tier\n",
    "        ORDER BY CASE risk_tier\n",
    "            WHEN 'Critical' THEN 1 WHEN 'High' THEN 2\n",
    "            WHEN 'Medium' THEN 3 ELSE 4 END\n",
    "    \"\"\")\n",
    "\n",
    "    detail_df = run_query(f\"\"\"\n",
    "        SELECT customer_key, risk_tier,\n",
    "               ROUND(churn_probability, 3) AS churn_prob,\n",
    "               ROUND(lifetime_value, 0) AS ltv, market_segment\n",
    "        FROM {GOLD}.gold_churn_scores\n",
    "        ORDER BY churn_probability DESC LIMIT 50\n",
    "    \"\"\")\n",
    "\n",
    "    return summary_df, detail_df\n",
    "\n",
    "\n",
    "# -- Tab: Executive Summary --------------------------------------------------------\n",
    "def exec_data():\n",
    "    \"\"\"Quarterly KPI roll-up with latest-quarter highlight.\"\"\"\n",
    "    df = run_query(f\"\"\"\n",
    "        SELECT year_quarter, total_orders, active_customers,\n",
    "               ROUND(gross_order_value, 0) AS gross_revenue,\n",
    "               ROUND(avg_order_value, 0) AS avg_order_value,\n",
    "               ROUND(revenue_per_customer, 0) AS rev_per_customer,\n",
    "               qoq_revenue_growth_pct AS qoq_growth\n",
    "        FROM {GOLD}.gold_executive_summary ORDER BY year_quarter\n",
    "    \"\"\")\n",
    "\n",
    "    if \"error\" in df.columns:\n",
    "        return \"Error loading data.\", df\n",
    "\n",
    "    if not df.empty:\n",
    "        q = df.iloc[-1]\n",
    "        header = f\"\"\"### Latest Quarter: {q['year_quarter']}\n",
    "\n",
    "| KPI | Value |\n",
    "|---|---|\n",
    "| Orders | {int(q['total_orders']):,} |\n",
    "| Active Customers | {int(q['active_customers']):,} |\n",
    "| Gross Revenue | ${float(q['gross_revenue']):,.0f} |\n",
    "| Avg Order Value | ${float(q['avg_order_value']):,.0f} |\n",
    "| Rev / Customer | ${float(q['rev_per_customer']):,.0f} |\n",
    "| QoQ Growth | {q['qoq_growth']}% |\n",
    "\"\"\"\n",
    "    else:\n",
    "        header = \"No data available.\"\n",
    "\n",
    "    return header, df\n",
    "\n",
    "\n",
    "# -- Gradio UI ---------------------------------------------------------------------\n",
    "with gr.Blocks(title=\"Retail Analytics\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"# Retail Analytics Dashboard\")\n",
    "    gr.Markdown(\"Gold-layer Delta tables served through Databricks SQL\")\n",
    "\n",
    "    with gr.Tab(\"Customer 360\"):\n",
    "        gr.Markdown(\n",
    "            \"Look up any customer to see their profile, RFM segment, and lifetime value.\"\n",
    "        )\n",
    "        with gr.Row():\n",
    "            c_id = gr.Textbox(label=\"Customer ID\", placeholder=\"e.g. 42\", scale=2)\n",
    "            c_btn = gr.Button(\"Look Up\", variant=\"primary\", scale=1)\n",
    "        c_md = gr.Markdown()\n",
    "        c_df = gr.Dataframe(label=\"Profile\")\n",
    "        c_btn.click(customer_lookup, inputs=[c_id], outputs=[c_md, c_df])\n",
    "\n",
    "    with gr.Tab(\"Revenue\"):\n",
    "        gr.Markdown(\"Monthly revenue trends. Filter by region and date range.\")\n",
    "        with gr.Row():\n",
    "            r_reg = gr.Dropdown(\n",
    "                [\"ALL\", \"AMERICA\", \"EUROPE\", \"ASIA\", \"AFRICA\", \"MIDDLE EAST\"],\n",
    "                value=\"ALL\", label=\"Region\",\n",
    "            )\n",
    "            r_s = gr.Textbox(label=\"Start (yyyy-MM)\", value=\"1995-01\")\n",
    "            r_e = gr.Textbox(label=\"End (yyyy-MM)\", value=\"1997-12\")\n",
    "            r_btn = gr.Button(\"Query\", variant=\"primary\")\n",
    "        r_hdr = gr.Markdown()\n",
    "        r_tbl = gr.Dataframe(label=\"Revenue Data\")\n",
    "        r_btn.click(revenue_data, inputs=[r_reg, r_s, r_e], outputs=[r_hdr, r_tbl])\n",
    "\n",
    "    with gr.Tab(\"Products\"):\n",
    "        gr.Markdown(\"Product performance aggregated by brand and price band.\")\n",
    "        with gr.Row():\n",
    "            p_sort = gr.Dropdown(\n",
    "                [\"revenue\", \"margin_pct\", \"return_rate\", \"orders\"],\n",
    "                value=\"revenue\", label=\"Sort By\",\n",
    "            )\n",
    "            p_n = gr.Slider(5, 50, value=20, step=5, label=\"Top N\")\n",
    "            p_btn = gr.Button(\"Query\", variant=\"primary\")\n",
    "        p_tbl = gr.Dataframe(label=\"Product Data\")\n",
    "        p_btn.click(product_data, inputs=[p_sort, p_n], outputs=[p_tbl])\n",
    "\n",
    "    with gr.Tab(\"Churn Risk\"):\n",
    "        gr.Markdown(\n",
    "            \"ML-predicted churn risk tiers and the 50 highest-risk customers.\"\n",
    "        )\n",
    "        ch_btn = gr.Button(\"Load Churn Data\", variant=\"primary\")\n",
    "        ch_summary = gr.Dataframe(label=\"Risk Tier Summary\")\n",
    "        ch_detail = gr.Dataframe(label=\"Top 50 At-Risk Customers\")\n",
    "        ch_btn.click(churn_data, outputs=[ch_summary, ch_detail])\n",
    "\n",
    "    with gr.Tab(\"Executive Summary\"):\n",
    "        gr.Markdown(\"Quarterly KPI roll-up across the full business.\")\n",
    "        ex_btn = gr.Button(\"Load KPIs\", variant=\"primary\")\n",
    "        ex_md = gr.Markdown()\n",
    "        ex_tbl = gr.Dataframe(label=\"All Quarters\")\n",
    "        ex_btn.click(exec_data, outputs=[ex_md, ex_tbl])\n",
    "\n",
    "demo.queue(default_concurrency_limit=100)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Starting Retail Analytics (catalog=%s)\", CATALOG)\n",
    "    demo.launch(server_name=\"0.0.0.0\", server_port=int(os.getenv(\"PORT\", \"8000\")))\n",
    "'''\n",
    "\n",
    "with open(f\"{APP_DIR}/app.py\", \"w\") as f:\n",
    "    f.write(app_source)\n",
    "print(f\"Wrote {APP_DIR}/app.py  ({len(app_source):,} chars)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Deploy\n",
    "\n",
    "This section:\n",
    "1. Creates the Databricks App with a SQL warehouse resource\n",
    "2. Grants the app's auto-provisioned service principal `SELECT` on Gold and Silver schemas\n",
    "3. Deploys the source code\n",
    "\n",
    "The service principal gets `CAN_USE` on the warehouse automatically through\n",
    "the resource binding."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from databricks.sdk.service.apps import (\n",
    "    App, AppDeployment, AppResource,\n",
    "    AppResourceSqlWarehouse, AppResourceSqlWarehouseSqlWarehousePermission,\n",
    ")\n",
    "\n",
    "sql_wh = AppResourceSqlWarehouse(\n",
    "    id=WAREHOUSE_ID,\n",
    "    permission=AppResourceSqlWarehouseSqlWarehousePermission.CAN_USE,\n",
    ")\n",
    "\n",
    "app_def = App(\n",
    "    name=APP_NAME,\n",
    "    description=\"Retail analytics dashboard -- Gold-layer Delta tables\",\n",
    "    default_source_code_path=APP_DIR,\n",
    "    resources=[AppResource(name=\"sql-warehouse\", sql_warehouse=sql_wh)],\n",
    ")\n",
    "\n",
    "try:\n",
    "    w.apps.create_and_wait(app=app_def)\n",
    "    print(f\"App created: {APP_NAME}\")\n",
    "except Exception as e:\n",
    "    if \"already exists\" in str(e):\n",
    "        print(f\"App '{APP_NAME}' already exists -- reusing\")\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "app_info = w.apps.get(name=APP_NAME)\n",
    "sp_id = getattr(app_info, \"service_principal_id\", None)\n",
    "sp_name = getattr(app_info, \"service_principal_name\", \"\") or \"\"\n",
    "print(f\"Service principal name: {sp_name}\")\n",
    "print(f\"Service principal id  : {sp_id}\")\n",
    "\n",
    "grant_principal = None\n",
    "if sp_id:\n",
    "    try:\n",
    "        sp_details = w.service_principals.get(id=sp_id)\n",
    "        grant_principal = sp_details.application_id\n",
    "        print(f\"Application ID        : {grant_principal}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if not grant_principal and sp_id:\n",
    "    grant_principal = str(sp_id)\n",
    "\n",
    "if grant_principal:\n",
    "    for stmt in [\n",
    "        f\"GRANT USE CATALOG ON CATALOG {CATALOG} TO `{grant_principal}`\",\n",
    "        f\"GRANT USE SCHEMA ON SCHEMA {GOLD} TO `{grant_principal}`\",\n",
    "        f\"GRANT USE SCHEMA ON SCHEMA {SILVER} TO `{grant_principal}`\",\n",
    "        f\"GRANT SELECT ON SCHEMA {GOLD} TO `{grant_principal}`\",\n",
    "        f\"GRANT SELECT ON SCHEMA {SILVER} TO `{grant_principal}`\",\n",
    "    ]:\n",
    "        try:\n",
    "            spark.sql(stmt)\n",
    "            tag = stmt.split(\"GRANT \")[1][:60]\n",
    "            print(f\"  Granted: {tag}\")\n",
    "        except Exception as ex:\n",
    "            print(f\"  Skipped: {str(ex)[:80]}\")\n",
    "else:\n",
    "    print(\"Could not resolve app SP. Grant permissions manually if queries fail.\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "deployment = AppDeployment(source_code_path=APP_DIR)\n",
    "\n",
    "try:\n",
    "    w.apps.deploy_and_wait(app_name=APP_NAME, app_deployment=deployment)\n",
    "except Exception as e:\n",
    "    if \"active deployment in progress\" in str(e).lower():\n",
    "        print(\"A deployment is already running. Wait for it to finish, then re-run this cell.\")\n",
    "    else:\n",
    "        print(f\"Deployment issue: {e}\")\n",
    "        print(f\"Manual fallback: open '{APP_NAME}' in Compute > Apps and click Deploy\")\n",
    "\n",
    "app_url = w.apps.get(name=APP_NAME).url\n",
    "print(f\"App URL: {app_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoke Test\n",
    "\n",
    "Run the same queries the app executes to verify Gold-layer data is accessible."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"1. Customer lookup (ID=42):\")\n",
    "display(spark.sql(f\"\"\"\n",
    "    SELECT c.customer_key, c.customer_name, c.market_segment, c.region_name,\n",
    "           r.rfm_segment, r.rfm_score, ROUND(r.monetary, 2) AS ltv\n",
    "    FROM {SILVER}.dim_customer c\n",
    "    LEFT JOIN {GOLD}.gold_customer_rfm r ON c.customer_key = r.customer_key\n",
    "    WHERE c.customer_key = 42\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\n2. Revenue (AMERICA, 1996):\")\n",
    "display(spark.sql(f\"\"\"\n",
    "    SELECT year_month, region, ROUND(SUM(net_revenue), 0) AS revenue\n",
    "    FROM {GOLD}.gold_monthly_sales\n",
    "    WHERE region = 'AMERICA' AND year_month >= '1996-01' AND year_month <= '1996-12'\n",
    "    GROUP BY year_month, region ORDER BY year_month\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\n3. Top 5 brands:\")\n",
    "display(spark.sql(f\"\"\"\n",
    "    SELECT brand, ROUND(SUM(net_revenue), 0) AS revenue\n",
    "    FROM {GOLD}.gold_product_performance\n",
    "    GROUP BY brand ORDER BY revenue DESC LIMIT 5\n",
    "\"\"\"))\n",
    "\n",
    "print(\"\\n4. Churn risk tiers:\")\n",
    "display(spark.sql(f\"\"\"\n",
    "    SELECT risk_tier, COUNT(*) AS customers,\n",
    "           ROUND(AVG(churn_probability), 3) AS avg_prob\n",
    "    FROM {GOLD}.gold_churn_scores\n",
    "    GROUP BY risk_tier\n",
    "    ORDER BY CASE risk_tier\n",
    "        WHEN 'Critical' THEN 1 WHEN 'High' THEN 2\n",
    "        WHEN 'Medium' THEN 3 ELSE 4 END\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "App deployed. Open the URL printed above to explore the dashboard.\n",
    "\n",
    "This is the last notebook -- the full pipeline is now live."
   ]
  }
 ]
}