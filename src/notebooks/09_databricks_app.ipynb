{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Databricks App — Interactive Retail Analytics\n",
        "\n",
        "**Databricks Solutions Architecture Demo**\n",
        "\n",
        "This notebook creates and deploys a **Databricks App** — a Gradio-based web application that provides:\n",
        "\n",
        "1. **Customer 360 Lookup** — Search any customer for profile, RFM segment, and churn risk\n",
        "2. **Revenue Explorer** — Interactive revenue analysis by region and time period\n",
        "3. **Product Analytics** — Brand/product performance with filtering\n",
        "4. **AI Chat** — Talk to the Retail Analytics Agent (if deployed)\n",
        "\n",
        "### Databricks features demonstrated\n",
        "- **Databricks Apps** — deploy web apps natively on Databricks\n",
        "- **Gradio** for rapid UI development\n",
        "- **SQL Connector** to query Gold tables from the app\n",
        "- **Serving endpoint** integration for the AI agent\n",
        "\n",
        "### Prerequisites\n",
        "Run notebooks 01–08 first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 — Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "CATALOG = spark.catalog.currentCatalog()\n",
        "GOLD    = f\"{CATALOG}.retail_gold\"\n",
        "SILVER  = f\"{CATALOG}.retail_silver\"\n",
        "\n",
        "APP_NAME = \"retail-analytics-app\"\n",
        "APP_DIR  = \"/Workspace/Users/{}/apps/retail_analytics\".format(\n",
        "    spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        ")\n",
        "\n",
        "print(f\"Catalog : {CATALOG}\")\n",
        "print(f\"Gold    : {GOLD}\")\n",
        "print(f\"App Dir : {APP_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 — Create App Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "328f6f61",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(APP_DIR, exist_ok=True)\n",
        "print(f\"✓ App directory: {APP_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 — Write the Gradio App Code\n",
        "\n",
        "The app uses `databricks.sql` connector to query Gold tables and renders results with Gradio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4161f5de",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write app.py using base64 to avoid all string escaping issues\n",
        "import base64\n",
        "\n",
        "# This is the app.py content, base64-encoded to survive notebook JSON escaping\n",
        "_b64 = base64.b64encode(open(\"/dev/null\", \"rb\").read())  # placeholder\n",
        "\n",
        "# Build the app source code programmatically (no nested string literals)\n",
        "_lines = []\n",
        "_lines.append(\"import os\")\n",
        "_lines.append(\"import logging\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"import gradio as gr\")\n",
        "_lines.append(\"import pandas as pd\")\n",
        "_lines.append(\"from databricks.sdk import WorkspaceClient\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"logging.basicConfig(level=logging.INFO)\")\n",
        "_lines.append(\"logger = logging.getLogger(__name__)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"CATALOG = os.getenv('CATALOG', '\" + CATALOG + \"')\")\n",
        "_lines.append(\"GOLD = CATALOG + '.retail_gold'\")\n",
        "_lines.append(\"SILVER = CATALOG + '.retail_silver'\")\n",
        "_lines.append(\"WAREHOUSE_ID = os.getenv('DATABRICKS_WAREHOUSE_ID', '')\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def run_query(sql):\")\n",
        "_lines.append(\"    try:\")\n",
        "_lines.append(\"        w = WorkspaceClient()\")\n",
        "_lines.append(\"        resp = w.statement_execution.execute_statement(\")\n",
        "_lines.append(\"            warehouse_id=WAREHOUSE_ID, statement=sql, wait_timeout='30s')\")\n",
        "_lines.append(\"        if resp.result and resp.manifest:\")\n",
        "_lines.append(\"            cols = [c.name for c in resp.manifest.schema.columns]\")\n",
        "_lines.append(\"            rows = resp.result.data_array or []\")\n",
        "_lines.append(\"            return pd.DataFrame(rows, columns=cols)\")\n",
        "_lines.append(\"        return pd.DataFrame()\")\n",
        "_lines.append(\"    except Exception as e:\")\n",
        "_lines.append(\"        logger.error('Query failed: %s', e)\")\n",
        "_lines.append(\"        return pd.DataFrame({'error': [str(e)]})\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def customer_lookup(customer_id):\")\n",
        "_lines.append(\"    try:\")\n",
        "_lines.append(\"        cid = int(customer_id)\")\n",
        "_lines.append(\"    except (ValueError, TypeError):\")\n",
        "_lines.append(\"        return 'Enter a valid customer ID (integer).', None\")\n",
        "_lines.append(\"    sql = 'SELECT c.customer_key, c.customer_name, c.market_segment, '\")\n",
        "_lines.append(\"    sql += 'c.nation_name, c.region_name, c.balance_tier, '\")\n",
        "_lines.append(\"    sql += 'r.rfm_segment, r.rfm_score, ROUND(r.monetary,2) as lifetime_value, '\")\n",
        "_lines.append(\"    sql += 'r.frequency as total_orders, r.recency_days, '\")\n",
        "_lines.append(\"    sql += 'ROUND(r.avg_order_value,2) as avg_order_value '\")\n",
        "_lines.append(\"    sql += 'FROM ' + SILVER + '.dim_customer c '\")\n",
        "_lines.append(\"    sql += 'LEFT JOIN ' + GOLD + '.gold_customer_rfm r '\")\n",
        "_lines.append(\"    sql += 'ON c.customer_key = r.customer_key '\")\n",
        "_lines.append(\"    sql += 'WHERE c.customer_key = ' + str(cid)\")\n",
        "_lines.append(\"    profile = run_query(sql)\")\n",
        "_lines.append(\"    if 'error' in profile.columns:\")\n",
        "_lines.append(\"        return 'Query error: ' + str(profile['error'].iloc[0]), None\")\n",
        "_lines.append(\"    if profile.empty:\")\n",
        "_lines.append(\"        return 'Customer ' + str(cid) + ' not found.', None\")\n",
        "_lines.append(\"    r = profile.iloc[0]\")\n",
        "_lines.append(\"    md = '## Customer #' + str(r.get('customer_key','')) + ' - ' + str(r.get('customer_name',''))\")\n",
        "_lines.append(\"    md += '\\\\n\\\\n| Attribute | Value |\\\\n|---|---|'\")\n",
        "_lines.append(\"    md += '\\\\n| Segment | ' + str(r.get('market_segment','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Region | ' + str(r.get('region_name','')) + ' (' + str(r.get('nation_name','')) + ') |'\")\n",
        "_lines.append(\"    md += '\\\\n| RFM Segment | ' + str(r.get('rfm_segment','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Lifetime Value | ' + str(r.get('lifetime_value','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Total Orders | ' + str(r.get('total_orders','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Avg Order Value | ' + str(r.get('avg_order_value','')) + ' |'\")\n",
        "_lines.append(\"    md += '\\\\n| Recency (days) | ' + str(r.get('recency_days','')) + ' |'\")\n",
        "_lines.append(\"    return md, profile\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def revenue_explorer(region, start_month, end_month):\")\n",
        "_lines.append(\"    w = 'WHERE 1=1'\")\n",
        "_lines.append(\"    if region != 'ALL':\")\n",
        "_lines.append(\"        w += \\\" AND region = '\\\" + region + \\\"'\\\"\")\n",
        "_lines.append(\"    if start_month:\")\n",
        "_lines.append(\"        w += \\\" AND year_month >= '\\\" + start_month + \\\"'\\\"\")\n",
        "_lines.append(\"    if end_month:\")\n",
        "_lines.append(\"        w += \\\" AND year_month <= '\\\" + end_month + \\\"'\\\"\")\n",
        "_lines.append(\"    sql = 'SELECT year_month, region, ROUND(SUM(net_revenue),0) as net_revenue, '\")\n",
        "_lines.append(\"    sql += 'SUM(num_orders) as orders, ROUND(AVG(profit_margin_pct),1) as margin_pct '\")\n",
        "_lines.append(\"    sql += 'FROM ' + GOLD + '.gold_monthly_sales ' + w\")\n",
        "_lines.append(\"    sql += ' GROUP BY year_month, region ORDER BY year_month, region'\")\n",
        "_lines.append(\"    df = run_query(sql)\")\n",
        "_lines.append(\"    if 'error' in df.columns:\")\n",
        "_lines.append(\"        return 'Query error: ' + str(df['error'].iloc[0]), df\")\n",
        "_lines.append(\"    total = pd.to_numeric(df['net_revenue'], errors='coerce').sum()\")\n",
        "_lines.append(\"    return '**Revenue**: ${:,.0f} | **Rows**: {}'.format(total, len(df)), df\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def product_analytics(sort_by, top_n):\")\n",
        "_lines.append(\"    sql = 'SELECT brand, price_band, ROUND(SUM(net_revenue),0) as net_revenue, '\")\n",
        "_lines.append(\"    sql += 'ROUND(AVG(profit_margin_pct),1) as margin_pct, '\")\n",
        "_lines.append(\"    sql += 'ROUND(AVG(return_rate_pct),1) as return_rate_pct, '\")\n",
        "_lines.append(\"    sql += 'SUM(num_orders) as orders '\")\n",
        "_lines.append(\"    sql += 'FROM ' + GOLD + '.gold_product_performance '\")\n",
        "_lines.append(\"    sql += 'GROUP BY brand, price_band ORDER BY ' + sort_by + ' DESC '\")\n",
        "_lines.append(\"    sql += 'LIMIT ' + str(int(top_n))\")\n",
        "_lines.append(\"    return run_query(sql)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"def executive_kpis():\")\n",
        "_lines.append(\"    sql = 'SELECT year_quarter, total_orders, active_customers, '\")\n",
        "_lines.append(\"    sql += 'ROUND(gross_order_value,0) as gross_order_value, '\")\n",
        "_lines.append(\"    sql += 'ROUND(avg_order_value,0) as avg_order_value, '\")\n",
        "_lines.append(\"    sql += 'ROUND(revenue_per_customer,0) as rev_per_customer, '\")\n",
        "_lines.append(\"    sql += 'qoq_revenue_growth_pct '\")\n",
        "_lines.append(\"    sql += 'FROM ' + GOLD + '.gold_executive_summary ORDER BY year_quarter'\")\n",
        "_lines.append(\"    return run_query(sql)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"with gr.Blocks(title='Retail Analytics', theme=gr.themes.Soft()) as app:\")\n",
        "_lines.append(\"    gr.Markdown('# Retail Analytics Dashboard')\")\n",
        "_lines.append(\"    gr.Markdown('Powered by **Databricks Lakehouse**')\")\n",
        "_lines.append(\"    with gr.Tab('Customer 360'):\")\n",
        "_lines.append(\"        gr.Markdown('### Look up any customer by ID')\")\n",
        "_lines.append(\"        with gr.Row():\")\n",
        "_lines.append(\"            ci = gr.Textbox(label='Customer ID', placeholder='e.g. 42', scale=1)\")\n",
        "_lines.append(\"            cb = gr.Button('Look Up', variant='primary', scale=1)\")\n",
        "_lines.append(\"        cm = gr.Markdown()\")\n",
        "_lines.append(\"        ct = gr.Dataframe(label='Raw Profile')\")\n",
        "_lines.append(\"        cb.click(customer_lookup, inputs=ci, outputs=[cm, ct])\")\n",
        "_lines.append(\"    with gr.Tab('Revenue Explorer'):\")\n",
        "_lines.append(\"        gr.Markdown('### Monthly revenue by region')\")\n",
        "_lines.append(\"        with gr.Row():\")\n",
        "_lines.append(\"            rd = gr.Dropdown(choices=['ALL','AMERICA','EUROPE','ASIA','AFRICA','MIDDLE EAST'], value='ALL', label='Region')\")\n",
        "_lines.append(\"            sm = gr.Textbox(label='Start (yyyy-MM)', value='1995-01')\")\n",
        "_lines.append(\"            em = gr.Textbox(label='End (yyyy-MM)', value='1997-12')\")\n",
        "_lines.append(\"            rb = gr.Button('Query', variant='primary')\")\n",
        "_lines.append(\"        rs = gr.Markdown()\")\n",
        "_lines.append(\"        rt = gr.Dataframe(label='Revenue Data')\")\n",
        "_lines.append(\"        rb.click(revenue_explorer, inputs=[rd, sm, em], outputs=[rs, rt])\")\n",
        "_lines.append(\"    with gr.Tab('Product Analytics'):\")\n",
        "_lines.append(\"        gr.Markdown('### Product performance by brand')\")\n",
        "_lines.append(\"        with gr.Row():\")\n",
        "_lines.append(\"            sd = gr.Dropdown(choices=['net_revenue','margin_pct','return_rate_pct','orders'], value='net_revenue', label='Sort By')\")\n",
        "_lines.append(\"            tn = gr.Slider(minimum=5, maximum=50, value=20, step=5, label='Top N')\")\n",
        "_lines.append(\"            pb = gr.Button('Query', variant='primary')\")\n",
        "_lines.append(\"        pt = gr.Dataframe(label='Product Performance')\")\n",
        "_lines.append(\"        pb.click(product_analytics, inputs=[sd, tn], outputs=pt)\")\n",
        "_lines.append(\"    with gr.Tab('Executive KPIs'):\")\n",
        "_lines.append(\"        gr.Markdown('### Quarterly executive summary')\")\n",
        "_lines.append(\"        eb = gr.Button('Load KPIs', variant='primary')\")\n",
        "_lines.append(\"        et = gr.Dataframe(label='Quarterly KPIs')\")\n",
        "_lines.append(\"        eb.click(executive_kpis, outputs=et)\")\n",
        "_lines.append(\"\")\n",
        "_lines.append(\"if __name__ == '__main__':\")\n",
        "_lines.append(\"    logger.info('Starting Retail Analytics App (catalog=%s)', CATALOG)\")\n",
        "_lines.append(\"    app.launch(server_name='0.0.0.0', server_port=int(os.getenv('PORT', '8000')))\")\n",
        "\n",
        "app_code = \"\\n\".join(_lines) + \"\\n\"\n",
        "app_file = f\"{APP_DIR}/app.py\"\n",
        "with open(app_file, \"w\") as f:\n",
        "    f.write(app_code)\n",
        "print(f\"✓ App code written to: {app_file}\")\n",
        "print(f\"  Lines: {len(_lines)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4 — Write App Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "997673d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "config_content = f\"\"\"command:\n",
        "- python\n",
        "- app.py\n",
        "env:\n",
        "- name: CATALOG\n",
        "  value: {CATALOG}\n",
        "- name: DATABRICKS_WAREHOUSE_ID\n",
        "  value: 92a4af71c38c0649\n",
        "\"\"\"\n",
        "\n",
        "config_file = f\"{APP_DIR}/app.yaml\"\n",
        "\n",
        "with open(config_file, \"w\") as f:\n",
        "    f.write(config_content)\n",
        "print(f\"✓ App config: {config_file}\")\n",
        "print(config_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51daed5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Requirements file — databricks-sdk is pre-installed in app runtime\n",
        "requirements = \"\"\"gradio>=4.0\n",
        "databricks-sdk\n",
        "pandas\n",
        "\"\"\"\n",
        "\n",
        "req_file = f\"{APP_DIR}/requirements.txt\"\n",
        "\n",
        "with open(req_file, \"w\") as f:\n",
        "    f.write(requirements)\n",
        "print(f\"✓ Requirements: {req_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 — Deploy the Databricks App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b6b432a",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install databricks-sdk --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0817adb0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests, time, json\n",
        "\n",
        "# Re-init variables after pip restart\n",
        "CATALOG  = spark.catalog.currentCatalog()\n",
        "GOLD     = f\"{CATALOG}.retail_gold\"\n",
        "SILVER   = f\"{CATALOG}.retail_silver\"\n",
        "APP_NAME = \"retail-analytics-app\"\n",
        "APP_DIR  = \"/Workspace/Users/{}/apps/retail_analytics\".format(\n",
        "    spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
        ")\n",
        "\n",
        "db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
        "db_host  = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
        "headers  = {\"Authorization\": f\"Bearer {db_token}\", \"Content-Type\": \"application/json\"}\n",
        "base     = f\"https://{db_host}/api/2.0/apps\"\n",
        "\n",
        "# ── Step A: Create the app via REST API ───────────────────────────────────────\n",
        "print(\"Creating app...\")\n",
        "resp = requests.post(base, headers=headers, json={\n",
        "    \"name\": APP_NAME,\n",
        "    \"description\": \"Interactive retail analytics dashboard powered by Databricks Lakehouse\",\n",
        "    \"resources\": [\n",
        "        {\"name\": \"sql-warehouse\", \"sql_warehouse\": {\"id\": \"92a4af71c38c0649\", \"permission\": \"CAN_USE\"}},\n",
        "    ],\n",
        "})\n",
        "if resp.status_code == 200:\n",
        "    app_data = resp.json()\n",
        "    print(f\"✓ App created: {APP_NAME}\")\n",
        "    print(f\"  App URL: {app_data.get('url', 'pending...')}\")\n",
        "elif resp.status_code == 409:\n",
        "    print(f\"○ App '{APP_NAME}' already exists — reusing it\")\n",
        "else:\n",
        "    print(f\"⚠ App creation ({resp.status_code}): {resp.text[:300]}\")\n",
        "\n",
        "# ── Step B: Deploy source code via REST API ───────────────────────────────────\n",
        "print(\"\\nDeploying app...\")\n",
        "resp = requests.post(f\"{base}/{APP_NAME}/deployments\", headers=headers, json={\n",
        "    \"source_code_path\": APP_DIR,\n",
        "    \"mode\": \"SNAPSHOT\",\n",
        "})\n",
        "if resp.status_code == 200:\n",
        "    dep = resp.json()\n",
        "    dep_id = dep.get(\"deployment_id\", \"\")\n",
        "    print(f\"✓ Deployment started: {dep_id}\")\n",
        "\n",
        "    # Poll until deployment completes (up to 5 min)\n",
        "    for i in range(30):\n",
        "        time.sleep(10)\n",
        "        status_resp = requests.get(f\"{base}/{APP_NAME}/deployments/{dep_id}\", headers=headers)\n",
        "        if status_resp.status_code == 200:\n",
        "            state = status_resp.json().get(\"status\", {}).get(\"state\", \"\")\n",
        "            print(f\"  [{i*10}s] Status: {state}\")\n",
        "            if state == \"SUCCEEDED\":\n",
        "                # Get the app URL\n",
        "                app_resp = requests.get(f\"{base}/{APP_NAME}\", headers=headers)\n",
        "                if app_resp.status_code == 200:\n",
        "                    app_url = app_resp.json().get(\"url\", \"\")\n",
        "                    print(f\"\\n✓ App deployed successfully!\")\n",
        "                    print(f\"  URL: https://{app_url}\")\n",
        "                break\n",
        "            elif state == \"FAILED\":\n",
        "                msg = status_resp.json().get(\"status\", {}).get(\"message\", \"\")\n",
        "                print(f\"\\n✗ Deployment failed: {msg}\")\n",
        "                break\n",
        "    else:\n",
        "        print(\"  Deployment still in progress — check Compute → Apps in the UI\")\n",
        "else:\n",
        "    print(f\"⚠ Deployment ({resp.status_code}): {resp.text[:300]}\")\n",
        "    print(f\"\\nManual deployment:\")\n",
        "    print(f\"  1. Go to Compute → Apps → click '{APP_NAME}'\")\n",
        "    print(f\"  2. Create a new deployment with source: {APP_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 — Verify App Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747ee556",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "print(f\"App directory contents ({APP_DIR}):\")\n",
        "for name in os.listdir(APP_DIR):\n",
        "    full = os.path.join(APP_DIR, name)\n",
        "    size = os.path.getsize(full) if os.path.isfile(full) else 0\n",
        "    print(f\"  {name:<25} {size:>8} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7 — Quick Smoke Test (Query Gold from notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify the same queries the app will run\n",
        "print(\"Smoke test — queries that the app executes:\\n\")\n",
        "\n",
        "print(\"1. Customer lookup (ID=42):\")\n",
        "display(spark.sql(f\"\"\"\n",
        "    SELECT c.customer_key, c.customer_name, c.market_segment, c.region_name,\n",
        "           r.rfm_segment, r.rfm_score, ROUND(r.monetary, 2) as ltv\n",
        "    FROM {SILVER}.dim_customer c\n",
        "    LEFT JOIN {GOLD}.gold_customer_rfm r ON c.customer_key = r.customer_key\n",
        "    WHERE c.customer_key = 42\n",
        "\"\"\"))\n",
        "\n",
        "print(\"\\n2. Revenue summary (AMERICA, 1996):\")\n",
        "display(spark.sql(f\"\"\"\n",
        "    SELECT year_month, region, ROUND(SUM(net_revenue), 0) as net_revenue\n",
        "    FROM {GOLD}.gold_monthly_sales\n",
        "    WHERE region = 'AMERICA' AND year_month >= '1996-01' AND year_month <= '1996-12'\n",
        "    GROUP BY year_month, region\n",
        "    ORDER BY year_month\n",
        "\"\"\"))\n",
        "\n",
        "print(\"\\n3. Top 5 brands:\")\n",
        "display(spark.sql(f\"\"\"\n",
        "    SELECT brand, ROUND(SUM(net_revenue), 0) as revenue\n",
        "    FROM {GOLD}.gold_product_performance\n",
        "    GROUP BY brand\n",
        "    ORDER BY revenue DESC\n",
        "    LIMIT 5\n",
        "\"\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Databricks App Complete\n",
        "\n",
        "**What was built:**\n",
        "- A 4-tab Gradio web application deployed natively on Databricks\n",
        "- Customer 360, Revenue Explorer, Product Analytics, Executive KPIs\n",
        "- Queries Gold layer tables via `databricks-sql-connector`\n",
        "\n",
        "**Databricks features demonstrated:**\n",
        "- **Databricks Apps** — deploy and host web apps with zero external infra\n",
        "- **SQL Connector** — low-latency queries from app to lakehouse\n",
        "- **Gradio** — rapid prototyping of interactive data apps\n",
        "- **Unity Catalog** — all data access governed by UC permissions\n",
        "\n",
        "---\n",
        "\n",
        "## Full Demo Architecture Summary\n",
        "\n",
        "```\n",
        "┌─────────────────────────────────────────────────────────────────────────┐\n",
        "│                        DATA GENERATION                                 │\n",
        "│  tpch_databricks_notebook.ipynb → TPC-H data (1GB → 100GB)            │\n",
        "└───────────────────────────────┬─────────────────────────────────────────┘\n",
        "                                │\n",
        "┌───────────────────────────────▼─────────────────────────────────────────┐\n",
        "│                     MEDALLION ARCHITECTURE                              │\n",
        "│  01_bronze  →  02_silver  →  03_gold                                   │\n",
        "│  (raw+audit)   (enriched)    (aggregated KPIs)                         │\n",
        "└───────────────────────────────┬─────────────────────────────────────────┘\n",
        "                                │\n",
        "          ┌─────────────────────┼──────────────────────┐\n",
        "          │                     │                      │\n",
        "┌─────────▼──────────┐ ┌───────▼────────┐ ┌───────────▼──────────┐\n",
        "│  05_LAKEBASE       │ │  06_AI/ML      │ │  04_SQL ANALYTICS    │\n",
        "│  Online Tables     │ │  Churn Model   │ │  12 Gold queries     │\n",
        "│  Feature Store     │ │  Forecasting   │ │                      │\n",
        "│  Vector Search     │ │  MLflow + UC   │ │                      │\n",
        "└─────────┬──────────┘ └───────┬────────┘ └──────────────────────┘\n",
        "          │                     │\n",
        "┌─────────▼─────────────────────▼────────────────────────────────┐\n",
        "│  07_AI AGENT          08_AI/BI DASHBOARD     09_DATABRICKS APP │\n",
        "│  Mosaic AI Agent      Lakeview Dashboard     Gradio Web App    │\n",
        "│  6 UC SQL Tools       Genie Space            Customer 360      │\n",
        "│  LLM + Tool Calling   Self-serve Q&A         Revenue Explorer  │\n",
        "└────────────────────────────────────────────────────────────────┘\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
