{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9ab78932",
      "metadata": {},
      "source": [
        "# AI Agent â€” Retail Analytics Assistant\n",
        "\n",
        "Tool-calling agent backed by Llama 3.3 70B (Foundation Model API) that answers\n",
        "natural-language questions using 6 Unity Catalog SQL functions as tools.\n",
        "\n",
        "```\n",
        "User Question  â”€â”€â–º  Llama 3.3 70B  â”€â”€â–º  Tool Selection\n",
        "                                         â”œâ”€â”€ Revenue       â†’ Gold Tables\n",
        "                                         â”œâ”€â”€ Customer      â†’ Customer RFM\n",
        "                                         â”œâ”€â”€ Product       â†’ Product Perf\n",
        "                                         â”œâ”€â”€ Churn         â†’ ML Scores\n",
        "                                         â”œâ”€â”€ Supplier      â†’ Supplier Scorecard\n",
        "                                         â””â”€â”€ Executive     â†’ Quarterly KPIs\n",
        "```\n",
        "\n",
        "**Prereqs**: Run notebooks 00â€“06 first."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd3c85d6",
      "metadata": {},
      "source": [
        "## 1 â€” Configuration & Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af3ee1d6",
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install databricks-sdk mlflow openai --quiet\n",
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98e56546",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import mlflow\n",
        "from pyspark.sql import functions as F\n",
        "from databricks.sdk import WorkspaceClient\n",
        "\n",
        "CATALOG = spark.catalog.currentCatalog()\n",
        "GOLD    = f\"{CATALOG}.retail_gold\"\n",
        "SILVER  = f\"{CATALOG}.retail_silver\"\n",
        "\n",
        "mlflow.set_registry_uri(\"databricks-uc\")\n",
        "w = WorkspaceClient()\n",
        "\n",
        "print(f\"Catalog  : {CATALOG}\")\n",
        "print(f\"Gold     : {GOLD}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39b3b2d6",
      "metadata": {},
      "source": [
        "---\n",
        "## 2 â€” Create Unity Catalog SQL Functions (Agent Tools)\n",
        "\n",
        "Each UC SQL function encapsulates a specific analytical capability. They are governed, discoverable in Unity Catalog, and can be reused by any agent or application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1234de6",
      "metadata": {},
      "outputs": [],
      "source": [
        "TOOLS_SCHEMA = f\"{CATALOG}.retail_agent_tools\"\n",
        "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {TOOLS_SCHEMA}\")\n",
        "print(f\"Tools schema: {TOOLS_SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97daa7d8",
      "metadata": {},
      "source": [
        "### Tool 1: Revenue by Region and Period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b20aa45a",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {TOOLS_SCHEMA}.get_revenue_by_region(\n",
        "    region_name STRING COMMENT 'Region name: AMERICA, EUROPE, ASIA, AFRICA, or MIDDLE EAST. Use ALL for all regions.',\n",
        "    start_month STRING COMMENT 'Start month in yyyy-MM format, e.g. 1995-01',\n",
        "    end_month STRING COMMENT 'End month in yyyy-MM format, e.g. 1995-12'\n",
        ")\n",
        "RETURNS TABLE(year_month STRING, region STRING, net_revenue DOUBLE, num_orders BIGINT, profit_margin_pct DOUBLE, yoy_growth_pct DOUBLE)\n",
        "COMMENT 'Returns monthly revenue, orders, margin, and YoY growth for a region and time period.'\n",
        "RETURN\n",
        "    SELECT year_month, region, ROUND(SUM(net_revenue), 2), SUM(num_orders), ROUND(AVG(profit_margin_pct), 2), ROUND(AVG(yoy_growth_pct), 2)\n",
        "    FROM {GOLD}.gold_monthly_sales\n",
        "    WHERE (region_name = 'ALL' OR region = region_name) AND year_month >= start_month AND year_month <= end_month\n",
        "    GROUP BY year_month, region ORDER BY year_month, region\n",
        "\"\"\")\n",
        "print(\"âœ“ get_revenue_by_region\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "21bfc7de",
      "metadata": {},
      "source": [
        "### Tool 2: Customer Profile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c7b0e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {TOOLS_SCHEMA}.get_customer_profile(\n",
        "    cust_key INT COMMENT 'Customer key (integer ID)'\n",
        ")\n",
        "RETURNS TABLE(customer_key INT, customer_name STRING, market_segment STRING, nation_name STRING, region_name STRING, balance_tier STRING, rfm_segment STRING, rfm_score INT, lifetime_value DOUBLE, frequency BIGINT, recency_days INT, avg_order_value DOUBLE)\n",
        "COMMENT 'Returns detailed customer profile including RFM segment, lifetime value, and geography.'\n",
        "RETURN\n",
        "    SELECT c.customer_key, c.customer_name, c.market_segment, c.nation_name, c.region_name, c.balance_tier,\n",
        "           r.rfm_segment, r.rfm_score, ROUND(r.monetary, 2), r.frequency, r.recency_days, ROUND(r.avg_order_value, 2)\n",
        "    FROM {SILVER}.dim_customer c LEFT JOIN {GOLD}.gold_customer_rfm r ON c.customer_key = r.customer_key\n",
        "    WHERE c.customer_key = cust_key\n",
        "\"\"\")\n",
        "print(\"âœ“ get_customer_profile\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6d73d9f",
      "metadata": {},
      "source": [
        "### Tool 3: Top Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51b6e30",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {TOOLS_SCHEMA}.get_top_products(\n",
        "    n INT COMMENT 'Number of top products to return (max 50)',\n",
        "    sort_by STRING COMMENT 'Sort metric: net_revenue, profit_margin_pct, return_rate_pct, or total_quantity_sold'\n",
        ")\n",
        "RETURNS TABLE(brand STRING, part_type STRING, price_band STRING, net_revenue DOUBLE, profit_margin_pct DOUBLE, return_rate_pct DOUBLE, total_quantity_sold DOUBLE, num_orders BIGINT)\n",
        "COMMENT 'Returns top N products sorted by the chosen metric.'\n",
        "RETURN\n",
        "    SELECT brand, part_type, price_band, net_revenue, profit_margin_pct, return_rate_pct, total_quantity_sold, num_orders\n",
        "    FROM {GOLD}.gold_product_performance\n",
        "    ORDER BY CASE sort_by WHEN 'net_revenue' THEN net_revenue WHEN 'profit_margin_pct' THEN profit_margin_pct WHEN 'return_rate_pct' THEN return_rate_pct WHEN 'total_quantity_sold' THEN total_quantity_sold ELSE net_revenue END DESC\n",
        "    LIMIT 50\n",
        "\"\"\")\n",
        "print(\"âœ“ get_top_products\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05ea922e",
      "metadata": {},
      "source": [
        "### Tool 4: Churn Risk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a725b2a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {TOOLS_SCHEMA}.get_churn_risk(\n",
        "    risk_level STRING COMMENT 'Risk tier: Critical, High, Medium, or Low. Use ALL for all tiers.',\n",
        "    top_n INT COMMENT 'Number of customers to return (max 100)'\n",
        ")\n",
        "RETURNS TABLE(customer_key INT, market_segment STRING, customer_region STRING, lifetime_value DOUBLE, rfm_score INT, churn_probability DOUBLE, risk_tier STRING)\n",
        "COMMENT 'Returns customers by churn risk tier, sorted by highest churn probability.'\n",
        "RETURN\n",
        "    SELECT customer_key, market_segment, customer_region, lifetime_value, rfm_score, churn_probability, risk_tier\n",
        "    FROM {GOLD}.gold_churn_scores\n",
        "    WHERE (risk_level = 'ALL' OR risk_tier = risk_level)\n",
        "    ORDER BY churn_probability DESC LIMIT 100\n",
        "\"\"\")\n",
        "print(\"âœ“ get_churn_risk\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17b3b24e",
      "metadata": {},
      "source": [
        "### Tool 5: Supplier Scorecard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360f8f04",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {TOOLS_SCHEMA}.get_supplier_scorecard(\n",
        "    region_filter STRING COMMENT 'Supplier region or ALL',\n",
        "    sort_metric STRING COMMENT 'Sort by: on_time_delivery_pct, net_revenue, profit_margin_pct, or return_rate_pct',\n",
        "    top_n INT COMMENT 'Number of suppliers to return (max 50)'\n",
        ")\n",
        "RETURNS TABLE(supplier_name STRING, supplier_nation STRING, supplier_region STRING, net_revenue DOUBLE, profit_margin_pct DOUBLE, on_time_delivery_pct DOUBLE, return_rate_pct DOUBLE, total_line_items BIGINT)\n",
        "COMMENT 'Returns supplier performance scorecard.'\n",
        "RETURN\n",
        "    SELECT supplier_name, supplier_nation, supplier_region, net_revenue, profit_margin_pct, on_time_delivery_pct, return_rate_pct, total_line_items\n",
        "    FROM {GOLD}.gold_supplier_scorecard\n",
        "    WHERE (region_filter = 'ALL' OR supplier_region = region_filter)\n",
        "    ORDER BY CASE sort_metric WHEN 'on_time_delivery_pct' THEN on_time_delivery_pct WHEN 'net_revenue' THEN net_revenue WHEN 'profit_margin_pct' THEN profit_margin_pct WHEN 'return_rate_pct' THEN -return_rate_pct ELSE on_time_delivery_pct END DESC\n",
        "    LIMIT 50\n",
        "\"\"\")\n",
        "print(\"âœ“ get_supplier_scorecard\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1429c0a2",
      "metadata": {},
      "source": [
        "### Tool 6: Executive Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772296e8",
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.sql(f\"\"\"\n",
        "CREATE OR REPLACE FUNCTION {TOOLS_SCHEMA}.get_executive_summary(\n",
        "    start_quarter STRING COMMENT 'Start quarter, e.g. 1995-Q1',\n",
        "    end_quarter STRING COMMENT 'End quarter, e.g. 1997-Q4'\n",
        ")\n",
        "RETURNS TABLE(year_quarter STRING, total_orders BIGINT, active_customers BIGINT, gross_order_value DOUBLE, avg_order_value DOUBLE, revenue_per_customer DOUBLE, qoq_revenue_growth_pct DOUBLE)\n",
        "COMMENT 'Returns quarterly executive KPI summary.'\n",
        "RETURN\n",
        "    SELECT year_quarter, total_orders, active_customers, gross_order_value, avg_order_value, revenue_per_customer, qoq_revenue_growth_pct\n",
        "    FROM {GOLD}.gold_executive_summary\n",
        "    WHERE year_quarter >= start_quarter AND year_quarter <= end_quarter\n",
        "    ORDER BY year_quarter\n",
        "\"\"\")\n",
        "print(\"âœ“ get_executive_summary\")\n",
        "print(f\"\\nAll 6 tools created in {TOOLS_SCHEMA}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "328e454f",
      "metadata": {},
      "source": [
        "---\n",
        "## 3 â€” Define Tool Specs (OpenAI function-calling format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cef774a",
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\"type\": \"function\", \"function\": {\"name\": \"get_revenue_by_region\", \"description\": \"Monthly revenue, orders, margin, YoY growth for a region and time period.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"region_name\": {\"type\": \"string\", \"description\": \"AMERICA, EUROPE, ASIA, AFRICA, MIDDLE EAST, or ALL\"}, \"start_month\": {\"type\": \"string\", \"description\": \"yyyy-MM\"}, \"end_month\": {\"type\": \"string\", \"description\": \"yyyy-MM\"}}, \"required\": [\"region_name\", \"start_month\", \"end_month\"]}}},\n",
        "    {\"type\": \"function\", \"function\": {\"name\": \"get_customer_profile\", \"description\": \"Customer profile with RFM segment, lifetime value, geography.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"cust_key\": {\"type\": \"integer\", \"description\": \"Customer ID\"}}, \"required\": [\"cust_key\"]}}},\n",
        "    {\"type\": \"function\", \"function\": {\"name\": \"get_top_products\", \"description\": \"Top N products by revenue, margin, return rate, or quantity.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"n\": {\"type\": \"integer\", \"description\": \"How many products\"}, \"sort_by\": {\"type\": \"string\", \"description\": \"net_revenue, profit_margin_pct, return_rate_pct, or total_quantity_sold\"}}, \"required\": [\"n\", \"sort_by\"]}}},\n",
        "    {\"type\": \"function\", \"function\": {\"name\": \"get_churn_risk\", \"description\": \"Customers by churn risk tier (Critical/High/Medium/Low/ALL).\", \"parameters\": {\"type\": \"object\", \"properties\": {\"risk_level\": {\"type\": \"string\", \"description\": \"Critical, High, Medium, Low, or ALL\"}, \"top_n\": {\"type\": \"integer\", \"description\": \"Number of customers\"}}, \"required\": [\"risk_level\", \"top_n\"]}}},\n",
        "    {\"type\": \"function\", \"function\": {\"name\": \"get_supplier_scorecard\", \"description\": \"Supplier reliability: on-time %, revenue, margin, return rate.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"region_filter\": {\"type\": \"string\", \"description\": \"Region or ALL\"}, \"sort_metric\": {\"type\": \"string\", \"description\": \"on_time_delivery_pct, net_revenue, profit_margin_pct, return_rate_pct\"}, \"top_n\": {\"type\": \"integer\", \"description\": \"Number of suppliers\"}}, \"required\": [\"region_filter\", \"sort_metric\", \"top_n\"]}}},\n",
        "    {\"type\": \"function\", \"function\": {\"name\": \"get_executive_summary\", \"description\": \"Quarterly KPIs: orders, customers, revenue, growth.\", \"parameters\": {\"type\": \"object\", \"properties\": {\"start_quarter\": {\"type\": \"string\", \"description\": \"yyyy-QN\"}, \"end_quarter\": {\"type\": \"string\", \"description\": \"yyyy-QN\"}}, \"required\": [\"start_quarter\", \"end_quarter\"]}}},\n",
        "]\n",
        "\n",
        "print(f\"{len(tools)} tool definitions ready\")\n",
        "for t in tools:\n",
        "    print(f\"  â€¢ {t['function']['name']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a31c609",
      "metadata": {},
      "source": [
        "## 4 â€” Tool Executor & Agent Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bc07aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def execute_tool(tool_name, arguments_json):\n",
        "    \"\"\"Execute a UC SQL function and return results as JSON string.\"\"\"\n",
        "    try:\n",
        "        args = json.loads(arguments_json)\n",
        "        fqn = f\"{TOOLS_SCHEMA}.{tool_name}\"\n",
        "        arg_list = [f\"'{v}'\" if isinstance(v, str) else str(v) for v in args.values()]\n",
        "        sql = f\"SELECT * FROM {fqn}({', '.join(arg_list)})\"\n",
        "        rows = spark.sql(sql).limit(50).toPandas().to_dict(orient='records')\n",
        "        return json.dumps(rows, default=str)\n",
        "    except Exception as e:\n",
        "        return json.dumps({\"error\": str(e)})\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT = \"\"\"You are a Retail Analytics AI Assistant. You have access to tools that query the company data warehouse.\n",
        "\n",
        "RULES:\n",
        "- Always use tools to look up data. Never make up numbers.\n",
        "- Format currency with $ and commas. Format percentages with %.\n",
        "- Provide business insights and actionable recommendations.\n",
        "- Keep responses concise but informative.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def ask_agent(question, max_iterations=5, verbose=True):\n",
        "    \"\"\"\n",
        "    Run the retail analytics agent: LLM reasons â†’ calls tools â†’ returns answer.\n",
        "    Uses Databricks Foundation Model API (OpenAI-compatible).\n",
        "    \"\"\"\n",
        "    from openai import OpenAI\n",
        "    # Get token and host from notebook context (works on all serverless runtimes)\n",
        "    db_token = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
        "    db_host  = spark.conf.get('spark.databricks.workspaceUrl')\n",
        "    client = OpenAI(api_key=db_token, base_url=f\"https://{db_host}/serving-endpoints\")\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": question},\n",
        "    ]\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"databricks-meta-llama-3-3-70b-instruct\",\n",
        "            messages=messages,\n",
        "            tools=tools,\n",
        "        )\n",
        "\n",
        "        choice = response.choices[0]\n",
        "\n",
        "        # If no tool calls, return the final answer\n",
        "        if choice.finish_reason == \"stop\" or not choice.message.tool_calls:\n",
        "            return choice.message.content\n",
        "\n",
        "        # Execute tool calls\n",
        "        messages.append(choice.message)\n",
        "        for tc in choice.message.tool_calls:\n",
        "            if verbose:\n",
        "                print(f\"  ðŸ”§ Calling {tc.function.name}({tc.function.arguments})\")\n",
        "            result = execute_tool(tc.function.name, tc.function.arguments)\n",
        "            messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": result})\n",
        "\n",
        "    return \"Reached max iterations. Try a simpler question.\"\n",
        "\n",
        "print(\"âœ“ Agent loop ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9735ff95",
      "metadata": {},
      "source": [
        "## 5 â€” Test the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46d90d98",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = ask_agent(\"What was the total revenue for AMERICA in 1996?\")\n",
        "print(f\"\\n{answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f977aba0",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = ask_agent(\"Show me the top 5 products by profit margin.\")\n",
        "print(f\"\\n{answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fb674c5",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = ask_agent(\"Which customers are at critical churn risk? Show me the top 5.\")\n",
        "print(f\"\\n{answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f509e5ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = ask_agent(\"Give me the executive summary for 1995 to 1997.\")\n",
        "print(f\"\\n{answer}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1705bc10",
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = ask_agent(\"Who are the most reliable suppliers in EUROPE? Rank the top 10.\")\n",
        "print(f\"\\n{answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e350902",
      "metadata": {},
      "source": [
        "## 6 â€” Log Agent Interactions to MLflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a27e67e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "experiment_name = f\"/Users/{spark.sql('SELECT current_user()').collect()[0][0]}/retail_agent_experiment\"\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "test_questions = [\n",
        "    \"What was total revenue for AMERICA in 1996?\",\n",
        "    \"Show me top 5 products by revenue.\",\n",
        "    \"Which customers have the highest churn risk?\",\n",
        "    \"Give me the quarterly executive summary for 1997.\",\n",
        "    \"Who are the most reliable suppliers in EUROPE?\",\n",
        "]\n",
        "\n",
        "with mlflow.start_run(run_name=\"agent_test_v1\"):\n",
        "    for i, q in enumerate(test_questions):\n",
        "        answer = ask_agent(q, verbose=False)\n",
        "        mlflow.log_param(f\"q{i+1}\", q[:100])\n",
        "        mlflow.log_text(answer or \"No answer\", f\"answers/q{i+1}.txt\")\n",
        "        print(f\"  âœ“ Q{i+1}: {q[:60]}...\")\n",
        "\n",
        "    mlflow.log_param(\"model\", \"databricks-meta-llama-3-3-70b-instruct\")\n",
        "    mlflow.log_param(\"num_tools\", len(tools))\n",
        "    mlflow.log_param(\"tool_names\", str([t['function']['name'] for t in tools]))\n",
        "\n",
        "print(f\"\\nâœ“ Agent interactions logged to MLflow\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82320d3c",
      "metadata": {},
      "source": [
        "## 7 â€” Interactive Agent (Run your own questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98230349",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Change the question below and re-run this cell to ask the agent anything!\n",
        "question = \"Compare revenue across all regions for 1997. Which region grew the fastest?\"\n",
        "\n",
        "print(f\"Q: {question}\\n\")\n",
        "answer = ask_agent(question)\n",
        "print(f\"\\nA: {answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9690087",
      "metadata": {},
      "source": [
        "---\n",
        "Agent is working â€” 6 UC SQL tools, Llama 3.3 70B, interactions logged to MLflow.\n",
        "\n",
        "Continue with `08_ai_bi_dashboard.ipynb`."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
